{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "tps-jul-22.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chirag314/TPS-July/blob/main/tps_jul_22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### References\n",
        "Inspiration was taken from these great notebooks:\n",
        "\n",
        "- https://www.kaggle.com/code/ambrosm/tpsjul22-gaussian-mixture-cluster-analysis\n",
        "- https://www.kaggle.com/code/ricopue/tps-jul22-clusters-and-lgb\n",
        "- https://www.kaggle.com/code/pourchot/simple-soft-voting\n",
        "- https://www.kaggle.com/code/hiro5299834/tps-jul-2022-unsupervised-and-supervised-learning\n",
        "- https://www.kaggle.com/code/karlcini/bayesiangmmclassifier\n",
        "\n",
        "Baseline Model: \n",
        "\n",
        "- https://www.kaggle.com/code/cabaxiom/tps-jul-22-gmm-baseline"
      ],
      "metadata": {
        "id": "JuFXl574uvRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklego"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "pBfncQPguvRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, PowerTransformer\n",
        "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
        "from sklego.mixture import BayesianGMMClassifier"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "pI-Q12uouvRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"../input/tabular-playground-series-jul-2022/data.csv\")\n",
        "df = df.drop(columns=\"id\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "5T1IYPX8uvRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_cols = [i for i in df.columns if df[i].dtype == int]\n",
        "float_cols = [i for i in df.columns if df[i].dtype == float]"
      ],
      "metadata": {
        "trusted": true,
        "id": "L_tImXPGuvRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = PowerTransformer()\n",
        "X_scaled = transformer.fit_transform(df)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns = df.columns)"
      ],
      "metadata": {
        "trusted": true,
        "id": "0mqp6K5ruvRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def components_number_multiple(max_n, n_seeds):\n",
        "    bic_scores = []\n",
        "    for n in range(2,max_n):\n",
        "        bic_scores_n = []\n",
        "        for seed in range(n_seeds):\n",
        "            gmm = GaussianMixture(n_components=n, covariance_type = 'full', n_init=3, random_state=seed)\n",
        "            gmm.fit(X_scaled)\n",
        "            bic_scores_n.append(gmm.bic(X_scaled))\n",
        "        bic_scores.append(bic_scores_n)\n",
        "    return bic_scores"
      ],
      "metadata": {
        "trusted": true,
        "id": "SdWafXDLuvRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_components_number_multiple(max_n, n_seeds):\n",
        "    bic_scores = components_number_multiple(max_n + 1, n_seeds)\n",
        "    bic_df = pd.DataFrame(data = bic_scores).T\n",
        "    bic_df.columns = range(2,max_n+1)\n",
        "    \n",
        "    f,ax = plt.subplots(figsize=(20,7))\n",
        "    for i in range(n_seeds):\n",
        "        sns.lineplot(x=bic_df.columns, y=bic_df.loc[i].values)\n",
        "    ax.set_xticks(range(2,max_n+1))\n",
        "    \n",
        "    return bic_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "aRy9QGpSuvRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = plot_components_number_multiple(max_n = 8, n_seeds = 1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "4ONtITgyuvRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bgmm = BayesianGaussianMixture(n_components=7, covariance_type = 'full', n_init=3, random_state=2)\n",
        "predicted_class = bgmm.fit_predict(X_scaled)\n",
        "df[\"class\"] = predicted_class"
      ],
      "metadata": {
        "trusted": true,
        "id": "T84jdt_EuvRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f,ax = plt.subplots(figsize=(25,50))\n",
        "for n,feature in enumerate(float_cols):\n",
        "    plt.subplot(8,3,n+1)\n",
        "    sns.kdeplot(data=df, x=feature, hue=\"class\", palette=sns.color_palette(\"hls\", 7));"
      ],
      "metadata": {
        "trusted": true,
        "id": "uJvg8kX_uvRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f,ax = plt.subplots(figsize=(25,20))\n",
        "for n,feature in enumerate(int_cols):\n",
        "    ax = plt.subplot(3,3,n+1)\n",
        "    sns.kdeplot(data=df, x=feature, hue=\"class\", bw_adjust=2, palette=sns.color_palette(\"hls\", 7));\n",
        "    ax.set_xlim([-2,30])"
      ],
      "metadata": {
        "trusted": true,
        "id": "5iqt0h72uvRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_cols = ['f_07','f_08', 'f_09', 'f_10','f_11', 'f_12', 'f_13', 'f_22','f_23', 'f_24', 'f_25','f_26','f_27', 'f_28']"
      ],
      "metadata": {
        "trusted": true,
        "id": "BDkkBjbQuvRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_clusters(X, predictions, silhouette = True, verbose=False):\n",
        "    \"\"\"Evaluate how good our cluster label predictions are\"\"\"\n",
        "    \n",
        "    db_score = davies_bouldin_score(X=X, labels=predictions)\n",
        "\n",
        "    ch_score = calinski_harabasz_score(X=X, labels=predictions)\n",
        "    #the silhouette score is the slowest to compute ~90 secs\n",
        "    s_score = silhouette_score(X=X, labels=predictions, metric='euclidean')\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"David Bouldin score: {0:0.4f}\".format(db_score))\n",
        "        print(\"Calinski Harabasz score: {0:0.3f}\".format(ch_score))\n",
        "        print(\"Silhouette score: {0:0.4f}\".format(s_score))\n",
        "        \n",
        "    return db_score, ch_score, s_score"
      ],
      "metadata": {
        "trusted": true,
        "id": "lbMjYte9uvRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def soft_voting(predict_number, best_cols = best_cols):\n",
        "    #initialise dataframe with 0's\n",
        "    predicted_probabilities = pd.DataFrame(np.zeros((len(df),7)), columns=range(1,8))\n",
        "    # loop with a different random seeds\n",
        "    for i in range(predict_number):\n",
        "        print(\"=========\", i, \"==========\")\n",
        "        X_scaled_sample = X_scaled.sample(40000)\n",
        "        gmm = BayesianGaussianMixture(n_components=7, covariance_type = 'full', max_iter=300, init_params=\"kmeans\", n_init=3, random_state=i)\n",
        "        gmm.fit(X_scaled_sample[best_cols])\n",
        "        pred_probs = gmm.predict_proba(X_scaled[best_cols])\n",
        "        pred_probs = pd.DataFrame(pred_probs, columns=range(1,8))\n",
        "        \n",
        "        # ensuring clusters are labeled the same value at each fit\n",
        "        if i == 0:\n",
        "            initial_centers = gmm.means_\n",
        "        new_classes = []\n",
        "        for mean2 in gmm.means_:\n",
        "            #for the current center of the current gmm, find the distances to every center in the initial gmm\n",
        "            distances = [np.linalg.norm(mean1-mean2) for mean1 in initial_centers]\n",
        "            # select the class with the minimum distance\n",
        "            new_class = np.argmin(distances) + 1 #add 1 as our labels are 1-7 but index is 0-6\n",
        "            new_classes.append(new_class)\n",
        "        # if the mapping from old cluster labels to new cluster labels isn't 1 to 1\n",
        "        if len(new_classes) != len(set(new_classes)):\n",
        "            print(\"iteration\", i, \"could not determine the cluster label mapping, skipping\")\n",
        "            continue\n",
        "        #apply the mapping by renaming the dataframe columns representing the original labels to the new labels    \n",
        "        pred_probs = pred_probs.rename(columns=dict(zip(range(1,8),new_classes)))\n",
        "        \n",
        "        #add the current prediction probabilities to the overall prediction probabilities\n",
        "        predicted_probabilities = predicted_probabilities + pred_probs\n",
        "        # lets score the cluster labels each iteration to see if soft voting is helpful\n",
        "        score_clusters(X_scaled[best_cols], predicted_probabilities.idxmax(axis=1), verbose=True)\n",
        "    \n",
        "    #normalise dataframe so each row sums to 1\n",
        "    predicted_probabilities = predicted_probabilities.div(predicted_probabilities.sum(axis=1), axis=0)\n",
        "    return predicted_probabilities"
      ],
      "metadata": {
        "trusted": true,
        "id": "oQB64UXmuvRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs = soft_voting(10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "pwAZyndsuvRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "score_clusters(X_scaled[best_cols],pred_probs.idxmax(axis=1), verbose=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Lv_JOkouuvRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_class(df):\n",
        "    new_df = df.copy()\n",
        "    new_df[\"highest_prob\"] = df.max(axis=1)\n",
        "    new_df[\"best_class\"] = df.idxmax(axis=1)\n",
        "    new_df[\"second_highest_prob\"] = df.apply(lambda x: x.nlargest(2).values[-1], axis=1)\n",
        "    new_df[\"second_best_class\"] = df.apply(lambda x: np.where(x == x.nlargest(2).values[-1])[0][0]+1, axis=1)\n",
        "    return new_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "6786BmizuvRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_class_probs = best_class(pred_probs)"
      ],
      "metadata": {
        "trusted": true,
        "id": "NmjoioN7uvRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_class_probs.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Rh39BCcxuvRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets visualise how confident our predictions are:"
      ],
      "metadata": {
        "id": "-wVw3ma7uvRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f,ax = plt.subplots(figsize=(20,7))\n",
        "sns.histplot(cluster_class_probs[\"highest_prob\"], bins=100);"
      ],
      "metadata": {
        "trusted": true,
        "id": "-Eh4qbRVuvRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_s = cluster_class_probs.groupby(\"best_class\")[\"highest_prob\"].mean()\n",
        "f,ax = plt.subplots(figsize=(8,6))\n",
        "sns.barplot(x=confidence_s.index, y = confidence_s.values, palette=sns.color_palette(\"hls\", 7) );\n",
        "ax.set_ylabel(\"Mean probability of point belonging to target class\");\n",
        "ax.set_ylim([0.65,0.95]);"
      ],
      "metadata": {
        "trusted": true,
        "id": "1vqHgTbxuvRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_highest_probs_sum = cluster_class_probs.groupby([\"best_class\",\"second_best_class\"])[\"second_highest_prob\"].sum().reset_index()\n",
        "\n",
        "f,ax = plt.subplots(figsize=(25,12))\n",
        "format_dataframe = pd.DataFrame({\"second_best_class\":range(1,8)})\n",
        "for i in range(1,8):\n",
        "    second_best_match_for_i = second_highest_probs_sum.loc[second_highest_probs_sum[\"best_class\"] == i, [\"second_best_class\",\"second_highest_prob\"]]\n",
        "    #We merge so that all classes 1 to 7 are available, we do this to keep colours consistent throughout plots\n",
        "    plot_df = pd.merge(left=format_dataframe, right=second_best_match_for_i, how=\"left\", on=\"second_best_class\")\n",
        "    ax = plt.subplot(2,4,i)\n",
        "    sns.barplot(data= plot_df, x=\"second_best_class\", y=\"second_highest_prob\",palette=sns.color_palette(\"hls\", 7) );\n",
        "    ax.set_ylabel(\"Probability sum\")\n",
        "    ax.set_title(\"Assigned Class: \" + str(i))\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "LUG-25bNuvRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confident_predictions = cluster_class_probs.loc[cluster_class_probs[\"highest_prob\"] >= 0.8]\n",
        "confident_predictions_class = confident_predictions[\"best_class\"]\n",
        "X_scaled[\"class\"] = confident_predictions_class"
      ],
      "metadata": {
        "trusted": true,
        "id": "66q411p5uvRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = X_scaled.loc[X_scaled[\"class\"] == X_scaled[\"class\"]]\n",
        "test_df = X_scaled.loc[X_scaled[\"class\"] != X_scaled[\"class\"]]"
      ],
      "metadata": {
        "trusted": true,
        "id": "TtC4DfqruvRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df.drop(columns=\"class\").reset_index(drop=True)\n",
        "y = train_df[\"class\"].reset_index(drop=True)\n",
        "X_test = test_df.drop(columns=\"class\").reset_index(drop=True)\n",
        "X_full = X_scaled.drop(columns=\"class\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "HOynMXyAuvRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_et = ExtraTreesClassifier(n_estimators = 2000,\n",
        "                                n_jobs = -1,\n",
        "                                random_state=42\n",
        "                               )"
      ],
      "metadata": {
        "trusted": true,
        "id": "dUxtAM9DuvRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lgbm = LGBMClassifier(objective = 'multiclass',\n",
        "                            n_estimators = 5000,\n",
        "                            random_state = 42,\n",
        "                            learning_rate = 0.1,\n",
        "                            n_jobs = -1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "gQZZJO2quvRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_qda = QuadraticDiscriminantAnalysis()\n",
        "model_lda = LinearDiscriminantAnalysis()"
      ],
      "metadata": {
        "trusted": true,
        "id": "RrQ70GaiuvRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bgmm = BayesianGMMClassifier(\n",
        "            n_components=7,\n",
        "            random_state = 1,\n",
        "            tol =1e-3,\n",
        "            covariance_type = 'full',\n",
        "            max_iter = 400,\n",
        "            n_init=4,\n",
        "            init_params='kmeans')"
      ],
      "metadata": {
        "trusted": true,
        "id": "ICKlnERbuvRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\"ET\":model_et, \"LGBM\":model_lgbm, \"QDA\":model_qda, \"LDA\":model_lda, \"BGMM_C\":model_bgmm}"
      ],
      "metadata": {
        "trusted": true,
        "id": "zo0K4r-NuvRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def k_fold_cv(model,X,y, verbose=True):\n",
        "    kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state = 0)\n",
        "\n",
        "    feature_imp, y_pred_list, y_true_list, acc_list  = [],[],[],[]\n",
        "    for fold, (train_index, val_index) in enumerate(kfold.split(X, y)):\n",
        "        if verbose: print(\"==fold==\", fold)\n",
        "        X_train = X.loc[train_index]\n",
        "        X_val = X.loc[val_index]\n",
        "\n",
        "        y_train = y.loc[train_index]\n",
        "        y_val = y.loc[val_index]\n",
        "\n",
        "        model.fit(X_train,y_train)\n",
        "\n",
        "        y_pred = model.predict(X_val)\n",
        "\n",
        "        y_pred_list = np.append(y_pred_list, y_pred)\n",
        "        y_true_list = np.append(y_true_list, y_val)\n",
        "\n",
        "        acc_list.append(accuracy_score(y_pred, y_val))\n",
        "        if verbose: print('Acc', accuracy_score(y_pred, y_val))\n",
        "\n",
        "        try:\n",
        "            feature_imp.append(model.feature_importances_)\n",
        "        except AttributeError: # if model does not have .feature_importances_ attribute\n",
        "            pass # returns empty list\n",
        "            \n",
        "    return feature_imp, y_pred_list, y_true_list, acc_list, X_val, y_val"
      ],
      "metadata": {
        "trusted": true,
        "id": "NqImdJFfuvRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_models():\n",
        "    for model_name, model in models.items():\n",
        "        print(\"===\",model_name,\"===\")\n",
        "        feature_imp, y_pred_list, y_true_list, acc_list, X_val, y_val = k_fold_cv(model=model,X=X,y=y, verbose=False)\n",
        "        acc_score = accuracy_score(y_pred_list, y_true_list)\n",
        "        print(\"{0:0.4f}\".format(acc_score))"
      ],
      "metadata": {
        "trusted": true,
        "id": "LQk22vWouvRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_models()"
      ],
      "metadata": {
        "trusted": true,
        "id": "YbBQa1TpuvRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature importance"
      ],
      "metadata": {
        "id": "MA2-zYaUuvRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_imp, y_pred_list, y_true_list, acc_list, X_val, y_val = k_fold_cv(model=model_lgbm,X=X,y=y)"
      ],
      "metadata": {
        "trusted": true,
        "id": "AywBzwySuvRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fold_feature_importances(model_importances, column_names, model_name, n_folds = 5, ax=None, boxplot=False):\n",
        "    importances_df = pd.DataFrame({\"feature_cols\": column_names, \"importances_fold_0\": model_importances[0]})\n",
        "    for i in range(1,n_folds):\n",
        "        importances_df[\"importances_fold_\"+str(i)] = model_importances[i]\n",
        "    importances_df[\"importances_fold_median\"] = importances_df.drop(columns=[\"feature_cols\"]).median(axis=1)\n",
        "    importances_df = importances_df.sort_values(by=\"importances_fold_median\", ascending=False)\n",
        "    if ax == None:\n",
        "        f, ax = plt.subplots(figsize=(15, 25))\n",
        "    if boxplot == False:\n",
        "        ax = sns.barplot(data = importances_df, x = \"importances_fold_median\", y=\"feature_cols\", color=\"blue\")\n",
        "        ax.set_xlabel(\"Median Feature importance across all folds\");\n",
        "    elif boxplot == True:\n",
        "        importances_df = importances_df.drop(columns=\"importances_fold_median\")\n",
        "        importances_df = importances_df.set_index(\"feature_cols\").stack().reset_index().rename(columns={0:\"feature_importance\"})\n",
        "        ax = sns.boxplot(data = importances_df, y = \"feature_cols\", x=\"feature_importance\", color=\"blue\", orient=\"h\")\n",
        "        ax.set_xlabel(\"Feature importance across all folds\");\n",
        "    plt.title(model_name)\n",
        "    ax.set_ylabel(\"Feature Columns\")\n",
        "    return ax"
      ],
      "metadata": {
        "trusted": true,
        "id": "VtgNhvgUuvRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(figsize=(15, 15))\n",
        "fold_feature_importances(model_importances = feature_imp, column_names = X_val.columns, model_name = \"LGBM\", n_folds = 2, ax=ax, boxplot=False);"
      ],
      "metadata": {
        "trusted": true,
        "id": "AAy2Gw5AuvRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_predict_all():\n",
        "    predictions = []\n",
        "    model_names = []\n",
        "    scores = []\n",
        "    for model_name, model in models.items():\n",
        "        print(\"===\",model_name,\"===\")\n",
        "        model.fit(X[best_cols], y)\n",
        "        preds_prob =  model.predict_proba(X_full[best_cols])\n",
        "        preds_prob_df = pd.DataFrame(preds_prob, columns=range(1,8), index=X_scaled.index)\n",
        "        db, ch, s = score_clusters(X_scaled[best_cols], preds_prob_df.idxmax(axis=1), verbose=True)\n",
        "        scores.append((db,ch,s))\n",
        "        predictions.append(preds_prob_df)\n",
        "        model_names.append(model_name)\n",
        "    \n",
        "    return predictions, model_names, scores\n",
        "    "
      ],
      "metadata": {
        "trusted": true,
        "id": "nqjA59TXuvRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, model_names, scores = fit_predict_all()"
      ],
      "metadata": {
        "trusted": true,
        "id": "i2Xe3jpKuvRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_class_probs = cluster_class_probs.loc[:,[1,2,3,4,5,6,7]]"
      ],
      "metadata": {
        "trusted": true,
        "id": "uImAmS5RuvRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.append(cluster_class_probs)\n",
        "model_names.append(\"BGMM\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "Bzm_IvnxuvRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db, ch, s = score_clusters(X_scaled[best_cols], cluster_class_probs.idxmax(axis=1), verbose=True)\n",
        "scores.append((db,ch,s))"
      ],
      "metadata": {
        "trusted": true,
        "id": "XjfrAbj2uvRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chosen fairly randomly\n",
        "predictions_df = 0.5 * predictions[0] + 1.5 * predictions[1] + 0.5 * predictions[2] + 1.5 * predictions[4] + 0.5 * predictions[5]\n",
        "\n",
        "#normalise so rows sums to 1\n",
        "predictions_df = predictions_df.div(predictions_df.sum(axis=1), axis=0)\n",
        "predictions_df = best_class(predictions_df)"
      ],
      "metadata": {
        "trusted": true,
        "id": "EnVFtRgLuvRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db, ch, s = score_clusters(X_scaled[best_cols], predictions_df[\"best_class\"], verbose=True)\n",
        "scores.append((db,ch,s))\n",
        "model_names.append(\"combined\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "u2f4uGPCuvRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(scores, index=model_names, columns=[\"Davies-Bouldin Index\",\"Calinski-Harabasz Index\",\"Silhouette Coefficient\"])"
      ],
      "metadata": {
        "trusted": true,
        "id": "ky2L29ISuvRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f,ax = plt.subplots(figsize=(10,5))\n",
        "val_c = predictions_df[\"best_class\"].value_counts()\n",
        "sns.barplot(x=val_c.index, y=val_c.values);"
      ],
      "metadata": {
        "trusted": true,
        "id": "HWpz3X-4uvRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(random_state = 10)\n",
        "X_pca = pca.fit_transform(X_scaled[best_cols])\n",
        "PCA_df = pd.DataFrame({\"PCA_1\" : X_pca[:,0], \"PCA_2\" : X_pca[:,1]})   \n",
        "PCA_df[\"class\"] = predictions_df[\"best_class\"]\n",
        "    \n",
        "f,ax = plt.subplots(figsize=(10, 10))\n",
        "sns.scatterplot(data = PCA_df, x = \"PCA_1\", y = \"PCA_2\", hue=\"class\", s=2, palette=sns.color_palette(\"hls\", PCA_df[\"class\"].nunique()));"
      ],
      "metadata": {
        "trusted": true,
        "id": "OoQlk45JuvRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_s = predictions_df.groupby(\"best_class\")[\"highest_prob\"].mean()\n",
        "f,ax = plt.subplots(figsize=(8,6))\n",
        "sns.barplot(x=confidence_s.index, y = confidence_s.values, palette=sns.color_palette(\"hls\", 7) );\n",
        "ax.set_ylabel(\"Mean probability of point belonging to target class\");\n",
        "ax.set_ylim([0.4,0.95]);"
      ],
      "metadata": {
        "trusted": true,
        "id": "hZKx5YoeuvRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_highest_probs_sum = predictions_df.groupby([\"best_class\",\"second_best_class\"])[\"second_highest_prob\"].sum().reset_index()\n",
        "\n",
        "f,ax = plt.subplots(figsize=(25,12))\n",
        "format_dataframe = pd.DataFrame({\"second_best_class\":range(1,8)})\n",
        "for i in range(1,8):\n",
        "    second_best_match_for_i = second_highest_probs_sum.loc[second_highest_probs_sum[\"best_class\"] == i, [\"second_best_class\",\"second_highest_prob\"]]\n",
        "    #We merge so that all classes 1 to 7 are available, we do this to keep colours consistent throughout plots\n",
        "    plot_df = pd.merge(left=format_dataframe, right=second_best_match_for_i, how=\"left\", on=\"second_best_class\")\n",
        "    ax = plt.subplot(2,4,i)\n",
        "    sns.barplot(data= plot_df, x=\"second_best_class\", y=\"second_highest_prob\",palette=sns.color_palette(\"hls\", 7) );\n",
        "    ax.set_ylabel(\"Probability sum\")\n",
        "    ax.set_title(\"Assigned Class: \" + str(i))\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "5JWoMTc6uvRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_predictions(predict_number, y):\n",
        "    for i in range(predict_number):\n",
        "        print(\"=========\", i, \"==========\")\n",
        "        X_scaled_sample = X_scaled.sample(60000)\n",
        "        y_sample = y.loc[X_scaled_sample.index]\n",
        "        \n",
        "        bgmmC = BayesianGMMClassifier(\n",
        "        n_components=7,\n",
        "        random_state = i,\n",
        "        tol =1e-3,\n",
        "        covariance_type = 'full',\n",
        "        max_iter = 300,\n",
        "        n_init=3,\n",
        "        init_params='kmeans')\n",
        "        \n",
        "        bgmmC.fit(X_scaled_sample[best_cols], y_sample)\n",
        "        \n",
        "        pred_probs = bgmmC.predict_proba(X_scaled[best_cols])\n",
        "        pred_probs = pd.DataFrame(pred_probs, columns=range(1,8))\n",
        "        \n",
        "        # lets score the cluster labels each iteration\n",
        "        score_clusters(X_scaled[best_cols], pred_probs.idxmax(axis=1), verbose=True)\n",
        "        y = pred_probs.idxmax(axis=1)\n",
        "        \n",
        "    return pred_probs"
      ],
      "metadata": {
        "trusted": true,
        "id": "C1QLgWn9uvRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities = update_predictions(predict_number=75, y=predictions_df[\"best_class\"])"
      ],
      "metadata": {
        "trusted": true,
        "id": "1zactEryuvRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = best_class(predicted_probabilities)"
      ],
      "metadata": {
        "trusted": true,
        "id": "6OiCaZA5uvRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_highest_probs_sum = predictions_df.groupby([\"best_class\",\"second_best_class\"])[\"second_highest_prob\"].sum().reset_index()\n",
        "\n",
        "f,ax = plt.subplots(figsize=(25,12))\n",
        "format_dataframe = pd.DataFrame({\"second_best_class\":range(1,8)})\n",
        "for i in range(1,8):\n",
        "    second_best_match_for_i = second_highest_probs_sum.loc[second_highest_probs_sum[\"best_class\"] == i, [\"second_best_class\",\"second_highest_prob\"]]\n",
        "    #We merge so that all classes 1 to 7 are available, we do this to keep colours consistent throughout plots\n",
        "    plot_df = pd.merge(left=format_dataframe, right=second_best_match_for_i, how=\"left\", on=\"second_best_class\")\n",
        "    ax = plt.subplot(2,4,i)\n",
        "    sns.barplot(data= plot_df, x=\"second_best_class\", y=\"second_highest_prob\",palette=sns.color_palette(\"hls\", 7) );\n",
        "    ax.set_ylabel(\"Probability sum\")\n",
        "    ax.set_title(\"Assigned Class: \" + str(i))"
      ],
      "metadata": {
        "trusted": true,
        "id": "23OiQ3WmuvRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f,ax = plt.subplots(figsize=(10,5))\n",
        "val_c = predictions_df[\"best_class\"].value_counts()\n",
        "sns.barplot(x=val_c.index, y=val_c.values);"
      ],
      "metadata": {
        "trusted": true,
        "id": "Iy5bNUf0uvRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submission"
      ],
      "metadata": {
        "id": "hR4UvUWfuvRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(\"../input/tabular-playground-series-jul-2022/sample_submission.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "5sbCfWbXuvRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission[\"Predicted\"] = predictions_df[\"best_class\"]\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "jNgbKmLtuvRZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}